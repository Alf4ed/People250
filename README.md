# People250 Dataset

The **People250** dataset consists of 250 images containing people, along with corresponding prompts and masks.

---

## ğŸ“‚ Dataset Structure

```plaintext
People250/
â”œâ”€â”€ original/                   # Original 250 images containing people
â”œâ”€â”€ prompts/                    # Prompts used for generation/inpainting (text format)
â”œâ”€â”€ masks/                      # Masks used during inpainting experiments
â”œâ”€â”€ clean_inpainted/            # Inpainted results without adversarial protection
â”‚   â”œâ”€â”€ baseline/               # Baseline results with default diffusion model
â”‚   â””â”€â”€ <other_experiments>     # Future inpainting results under various settings
â”œâ”€â”€ adversarial/                # Adversarial protection experiments
â”‚   â”œâ”€â”€ <experiment_name>/      # E.g., "DiffJPEG experiments", "Original DDD"
â”‚   â”‚   â”œâ”€â”€ protected/          # Watermarked/protected images
â”‚   â”‚   â””â”€â”€ generated/          # Output after running diffusion models
â”œâ”€â”€ metadata/                   # Details of experiment configurations
â”‚   â””â”€â”€ <experiment_name>.md    # Experiment-specific parameters (seed, model settings, etc.)
â””â”€â”€ README.md                   # This file
```

## ğŸ” Folder Details

> ğŸ“ Filenames
>
> Filenames of protected and generated images should be identical to the corresponding original image, i.e., `1234.png`.

`original/`

* Contains the 250 original images featuring people.
* These are untouched and serve as the baseline for all experiments.

`prompts/`

* Text files containing the prompts used for inpainting.
* File naming convention matches original/ for easy cross-referencing.

`masks/`

* Contains binary masks used during inpainting.
* Masks correspond to regions in `original/` images that were targeted for inpainting.

`clean_inpainted/`

* Contains inpainting results without adversarial protection.
* Useful as a baseline for evaluating the effectiveness of adversarial methods.

**Example Subfolders:**

* `/baseline/`: Inpainting using standard diffusion models.
* `/<experiment_name>/`: Future experiments with varied parameters (e.g., different inpainting strengths and guidance scales).

`adversarial/`

* Contains adversarial protection experiments, including watermarked images and the resulting generated images after running stable diffusion inpainting.

**Example Subfolders:**

```plaintext
adversarial/
â”œâ”€â”€ optimised_ddd/
â”‚   â”œâ”€â”€ protected/    # Watermarked images from Jakub's optimised DDD
â”‚   â””â”€â”€ generated/    # Diffusion model outputs after protection
â”œâ”€â”€ photoguard/
â”‚   â”œâ”€â”€ protected/    # Photoguard-protected images
â”‚   â””â”€â”€ generated/    # Corresponding generated results
```

`metadata/`

* Stores experiment settings.
* Ensures reproducibility by recording parameters like:
    * Diffusion model
    * Diffusion model settings
    * Random seeds
    * Adversarial settings

An example is stored as `template.md`.

## ğŸƒ Usage Instructions

### ğŸ”„ Cloning the Repository
```bash
git clone https://github.com/Alf4ed/fourth-year-project-dataset.git
```

## ğŸ§ª Running Experiments
To ensure consistency with recorded experiments:

1. Check the corresponding `metadata/` file for settings.
2. Use `original/`, `prompts/`, and `masks/` as inputs.
3. Output results should follow the `adversarial/<experiment_name>/` or `clean_inpainted/<experiment_name>/` structure.

## ğŸ¤ Related Repository
This dataset complements the main project repository:

ğŸ‘‰ Main Project: [Diffusion Based Adversarial Perturbations for Disrupting Deepfake Generation](https://github.com/JakubCzarlinski/fourth-year-project)
